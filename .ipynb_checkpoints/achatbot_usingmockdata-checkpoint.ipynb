{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b752bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "\n",
    "\n",
    "import json \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ce1cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []\n",
    "responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85c0dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])\n",
    "        \n",
    "# using an if here because tags can repeat    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "        \n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85f3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba2f6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target labels into a model understandable form.\n",
    "# “LabelEncoder()” function provided by scikit-learn\n",
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels = lbl_encoder.transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a08bf484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 3, 3, 3, 7, 7, 7, 7, 0, 0, 0, 6, 6, 6, 5, 5, 5, 5,\n",
       "       5, 5, 5, 2, 2, 2, 2, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50e06c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000 # the number of words to keep, based on frequency\n",
    "# why we limit vocab size?\n",
    "# we don’t want every unique token in our vocabulary. If it doesn’t appear at \n",
    "# least twice then might just be a spelling mistake or a \n",
    "# word we can’t learn anything about it if it doesn’t appear that often.\n",
    "\n",
    "# we might think that low frequency words (especially hapax legomena) \n",
    "# don't tell us very much useful information! And practically, this is often true; you don't \n",
    "# benefit from increasing the vocab size past a certain point, \n",
    "# but you will continue to incur increasing memory and performance costs associated with a larger input representation.\n",
    "\n",
    "embedding_dim = 16\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\" # oov_token is a value for “out of token”\n",
    "\n",
    "# Tokenization is a method to segregate a particular text into small chunks or tokens. \n",
    "# Here the tokens or chunks can be anything from words to characters, even subwords.\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "\n",
    "# fitting the tokenizer on training sentences\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "# the index of the words in tokenizer. this is a dict\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# texts_to_sequences method in tokenizer class helps in converting tokens of text corpus into a sequence of integers.\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "\n",
    "# The “pad_sequences” method is used to make all the training text sequences into the same size.\n",
    "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b85dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7367809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 20, 16)            16000     \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,680\n",
      "Trainable params: 16,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model training using sequential model of keras\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e0e1c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0800 - accuracy: 0.15 - 0s 4ms/step - loss: 2.0800 - accuracy: 0.1515\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0782 - accuracy: 0.15 - 0s 4ms/step - loss: 2.0783 - accuracy: 0.1515\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0771 - accuracy: 0.15 - 0s 4ms/step - loss: 2.0775 - accuracy: 0.1515\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0765 - accuracy: 0.18 - 0s 4ms/step - loss: 2.0767 - accuracy: 0.1818\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0751 - accuracy: 0.18 - 0s 3ms/step - loss: 2.0761 - accuracy: 0.1818\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0761 - accuracy: 0.28 - 0s 4ms/step - loss: 2.0758 - accuracy: 0.3030\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0757 - accuracy: 0.34 - 0s 3ms/step - loss: 2.0754 - accuracy: 0.3636\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0751 - accuracy: 0.25 - 0s 4ms/step - loss: 2.0750 - accuracy: 0.2424\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0734 - accuracy: 0.28 - 0s 4ms/step - loss: 2.0744 - accuracy: 0.2727\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0729 - accuracy: 0.28 - 0s 4ms/step - loss: 2.0737 - accuracy: 0.2727\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0738 - accuracy: 0.21 - 0s 3ms/step - loss: 2.0733 - accuracy: 0.2424\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0727 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0731 - accuracy: 0.2121\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0735 - accuracy: 0.15 - 0s 4ms/step - loss: 2.0730 - accuracy: 0.1818\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0723 - accuracy: 0.12 - 0s 3ms/step - loss: 2.0727 - accuracy: 0.1212\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0717 - accuracy: 0.12 - 0s 4ms/step - loss: 2.0724 - accuracy: 0.1212\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0728 - accuracy: 0.09 - 0s 4ms/step - loss: 2.0721 - accuracy: 0.1212\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0710 - accuracy: 0.12 - 0s 4ms/step - loss: 2.0719 - accuracy: 0.1212\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0723 - accuracy: 0.09 - 0s 4ms/step - loss: 2.0716 - accuracy: 0.1212\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0704 - accuracy: 0.12 - 0s 3ms/step - loss: 2.0712 - accuracy: 0.1212\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0703 - accuracy: 0.12 - 0s 3ms/step - loss: 2.0708 - accuracy: 0.1212\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0698 - accuracy: 0.12 - 0s 4ms/step - loss: 2.0704 - accuracy: 0.1212\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0697 - accuracy: 0.12 - 0s 5ms/step - loss: 2.0700 - accuracy: 0.1212\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0689 - accuracy: 0.12 - 0s 3ms/step - loss: 2.0696 - accuracy: 0.1212\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0686 - accuracy: 0.12 - 0s 4ms/step - loss: 2.0693 - accuracy: 0.1212\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0694 - accuracy: 0.12 - 0s 4ms/step - loss: 2.0689 - accuracy: 0.1212\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0687 - accuracy: 0.18 - 0s 3ms/step - loss: 2.0684 - accuracy: 0.1818\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0681 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0675 - accuracy: 0.2424\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0670 - accuracy: 0.31 - 0s 3ms/step - loss: 2.0667 - accuracy: 0.3030\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0661 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0656 - accuracy: 0.2424\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0650 - accuracy: 0.25 - 0s 4ms/step - loss: 2.0645 - accuracy: 0.2424\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0628 - accuracy: 0.25 - 0s 4ms/step - loss: 2.0633 - accuracy: 0.2424\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0629 - accuracy: 0.25 - 0s 4ms/step - loss: 2.0620 - accuracy: 0.2424\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0604 - accuracy: 0.37 - 0s 4ms/step - loss: 2.0609 - accuracy: 0.3636\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0601 - accuracy: 0.37 - 0s 4ms/step - loss: 2.0600 - accuracy: 0.3636\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0578 - accuracy: 0.31 - 0s 4ms/step - loss: 2.0592 - accuracy: 0.3030\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0597 - accuracy: 0.28 - 0s 4ms/step - loss: 2.0584 - accuracy: 0.3030\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0577 - accuracy: 0.31 - 0s 5ms/step - loss: 2.0576 - accuracy: 0.3030\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0546 - accuracy: 0.31 - 0s 4ms/step - loss: 2.0566 - accuracy: 0.3030\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0564 - accuracy: 0.31 - 0s 4ms/step - loss: 2.0553 - accuracy: 0.3030\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0540 - accuracy: 0.31 - 0s 4ms/step - loss: 2.0538 - accuracy: 0.3030\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0542 - accuracy: 0.34 - 0s 5ms/step - loss: 2.0522 - accuracy: 0.3636\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0516 - accuracy: 0.37 - 0s 4ms/step - loss: 2.0513 - accuracy: 0.3636\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0486 - accuracy: 0.25 - 0s 4ms/step - loss: 2.0506 - accuracy: 0.2424\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0520 - accuracy: 0.18 - 0s 4ms/step - loss: 2.0497 - accuracy: 0.2121\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0503 - accuracy: 0.21 - 0s 3ms/step - loss: 2.0490 - accuracy: 0.2121\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0460 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0479 - accuracy: 0.2121\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0446 - accuracy: 0.21 - 0s 3ms/step - loss: 2.0467 - accuracy: 0.2121\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0432 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0457 - accuracy: 0.2121\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0480 - accuracy: 0.18 - 0s 4ms/step - loss: 2.0447 - accuracy: 0.2121\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0442 - accuracy: 0.21 - 0s 3ms/step - loss: 2.0435 - accuracy: 0.2121\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0434 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0422 - accuracy: 0.2121\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0383 - accuracy: 0.21 - 0s 3ms/step - loss: 2.0406 - accuracy: 0.2121\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0365 - accuracy: 0.21 - 0s 3ms/step - loss: 2.0388 - accuracy: 0.2121\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0380 - accuracy: 0.21 - 0s 3ms/step - loss: 2.0376 - accuracy: 0.2121\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0349 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0367 - accuracy: 0.2121\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0361 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0356 - accuracy: 0.2121\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0327 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0346 - accuracy: 0.2121\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0352 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0337 - accuracy: 0.2121\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 2.0343 - accuracy: 0.25 - 0s 3ms/step - loss: 2.0328 - accuracy: 0.2424\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0303 - accuracy: 0.28 - 0s 3ms/step - loss: 2.0318 - accuracy: 0.2727\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0327 - accuracy: 0.34 - 0s 4ms/step - loss: 2.0307 - accuracy: 0.3636\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0320 - accuracy: 0.34 - 0s 4ms/step - loss: 2.0298 - accuracy: 0.3636\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0320 - accuracy: 0.28 - 0s 4ms/step - loss: 2.0289 - accuracy: 0.3030\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0299 - accuracy: 0.28 - 0s 4ms/step - loss: 2.0273 - accuracy: 0.3030\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0262 - accuracy: 0.31 - 0s 4ms/step - loss: 2.0250 - accuracy: 0.3030\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0172 - accuracy: 0.37 - 0s 4ms/step - loss: 2.0224 - accuracy: 0.3636\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0149 - accuracy: 0.37 - 0s 4ms/step - loss: 2.0203 - accuracy: 0.3636\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0152 - accuracy: 0.37 - 0s 4ms/step - loss: 2.0189 - accuracy: 0.3636\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0223 - accuracy: 0.34 - 0s 4ms/step - loss: 2.0175 - accuracy: 0.3636\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0140 - accuracy: 0.25 - 0s 4ms/step - loss: 2.0162 - accuracy: 0.2424\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0133 - accuracy: 0.25 - 0s 5ms/step - loss: 2.0144 - accuracy: 0.2424\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0076 - accuracy: 0.21 - 0s 4ms/step - loss: 2.0126 - accuracy: 0.2121\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0057 - accuracy: 0.28 - 0s 4ms/step - loss: 2.0107 - accuracy: 0.2727\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0146 - accuracy: 0.28 - 0s 4ms/step - loss: 2.0091 - accuracy: 0.3030\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0058 - accuracy: 0.34 - 0s 3ms/step - loss: 2.0078 - accuracy: 0.3333\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0105 - accuracy: 0.31 - 0s 3ms/step - loss: 2.0063 - accuracy: 0.3333\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0007 - accuracy: 0.34 - 0s 3ms/step - loss: 2.0050 - accuracy: 0.3333\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9986 - accuracy: 0.34 - 0s 3ms/step - loss: 2.0038 - accuracy: 0.3333\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9975 - accuracy: 0.34 - 0s 4ms/step - loss: 2.0025 - accuracy: 0.3333\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0003 - accuracy: 0.34 - 0s 3ms/step - loss: 2.0015 - accuracy: 0.3333\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9994 - accuracy: 0.34 - 0s 3ms/step - loss: 2.0004 - accuracy: 0.3333\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0044 - accuracy: 0.31 - 0s 3ms/step - loss: 1.9993 - accuracy: 0.3333\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9983 - accuracy: 0.34 - 0s 3ms/step - loss: 1.9984 - accuracy: 0.3333\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9994 - accuracy: 0.31 - 0s 3ms/step - loss: 1.9981 - accuracy: 0.3030\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9971 - accuracy: 0.31 - 0s 3ms/step - loss: 1.9971 - accuracy: 0.3030\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0018 - accuracy: 0.28 - 0s 4ms/step - loss: 1.9959 - accuracy: 0.3030\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9957 - accuracy: 0.31 - 0s 4ms/step - loss: 1.9947 - accuracy: 0.3030\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9991 - accuracy: 0.28 - 0s 4ms/step - loss: 1.9924 - accuracy: 0.3030\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9847 - accuracy: 0.31 - 0s 3ms/step - loss: 1.9895 - accuracy: 0.3030\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9814 - accuracy: 0.34 - 0s 4ms/step - loss: 1.9863 - accuracy: 0.3333\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9840 - accuracy: 0.34 - 0s 3ms/step - loss: 1.9829 - accuracy: 0.3333\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9782 - accuracy: 0.34 - 0s 4ms/step - loss: 1.9794 - accuracy: 0.3333\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9799 - accuracy: 0.31 - 0s 3ms/step - loss: 1.9762 - accuracy: 0.3333\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9727 - accuracy: 0.34 - 0s 4ms/step - loss: 1.9725 - accuracy: 0.3333\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9777 - accuracy: 0.31 - 0s 3ms/step - loss: 1.9704 - accuracy: 0.3333\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9736 - accuracy: 0.34 - 0s 4ms/step - loss: 1.9680 - accuracy: 0.3636\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9583 - accuracy: 0.40 - 0s 3ms/step - loss: 1.9662 - accuracy: 0.3939\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9594 - accuracy: 0.40 - 0s 4ms/step - loss: 1.9635 - accuracy: 0.3939\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9683 - accuracy: 0.37 - 0s 3ms/step - loss: 1.9609 - accuracy: 0.3939\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9500 - accuracy: 0.40 - 0s 4ms/step - loss: 1.9577 - accuracy: 0.3939\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9553 - accuracy: 0.37 - 0s 3ms/step - loss: 1.9539 - accuracy: 0.3636\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9597 - accuracy: 0.34 - 0s 4ms/step - loss: 1.9500 - accuracy: 0.3636\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9399 - accuracy: 0.37 - 0s 3ms/step - loss: 1.9467 - accuracy: 0.3636\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9517 - accuracy: 0.34 - 0s 4ms/step - loss: 1.9438 - accuracy: 0.3636\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9351 - accuracy: 0.37 - 0s 3ms/step - loss: 1.9418 - accuracy: 0.3636\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9414 - accuracy: 0.34 - 0s 3ms/step - loss: 1.9406 - accuracy: 0.3333\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9400 - accuracy: 0.34 - 0s 3ms/step - loss: 1.9392 - accuracy: 0.3333\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9431 - accuracy: 0.31 - 0s 3ms/step - loss: 1.9371 - accuracy: 0.3333\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9281 - accuracy: 0.34 - 0s 3ms/step - loss: 1.9336 - accuracy: 0.3333\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9212 - accuracy: 0.34 - 0s 3ms/step - loss: 1.9293 - accuracy: 0.3333\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9273 - accuracy: 0.37 - 0s 3ms/step - loss: 1.9253 - accuracy: 0.3636\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9160 - accuracy: 0.37 - 0s 4ms/step - loss: 1.9219 - accuracy: 0.3636\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9221 - accuracy: 0.37 - 0s 3ms/step - loss: 1.9198 - accuracy: 0.3636\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9271 - accuracy: 0.37 - 0s 4ms/step - loss: 1.9188 - accuracy: 0.3939\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9122 - accuracy: 0.40 - 0s 3ms/step - loss: 1.9166 - accuracy: 0.3939\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9172 - accuracy: 0.37 - 0s 4ms/step - loss: 1.9139 - accuracy: 0.3939\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.9075 - accuracy: 0.40 - 0s 3ms/step - loss: 1.9113 - accuracy: 0.3939\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8999 - accuracy: 0.40 - 0s 3ms/step - loss: 1.9092 - accuracy: 0.3939\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9163 - accuracy: 0.37 - 0s 3ms/step - loss: 1.9064 - accuracy: 0.3939\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8990 - accuracy: 0.40 - 0s 3ms/step - loss: 1.9030 - accuracy: 0.3939\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8841 - accuracy: 0.40 - 0s 3ms/step - loss: 1.8997 - accuracy: 0.3939\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9007 - accuracy: 0.40 - 0s 5ms/step - loss: 1.8968 - accuracy: 0.4242\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8888 - accuracy: 0.43 - 0s 5ms/step - loss: 1.8942 - accuracy: 0.4242\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8814 - accuracy: 0.43 - 0s 3ms/step - loss: 1.8906 - accuracy: 0.4242\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8926 - accuracy: 0.40 - 0s 4ms/step - loss: 1.8866 - accuracy: 0.4242\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8854 - accuracy: 0.37 - 0s 3ms/step - loss: 1.8828 - accuracy: 0.3939\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8762 - accuracy: 0.40 - 0s 4ms/step - loss: 1.8786 - accuracy: 0.3939\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8852 - accuracy: 0.37 - 0s 3ms/step - loss: 1.8752 - accuracy: 0.3939\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8748 - accuracy: 0.37 - 0s 4ms/step - loss: 1.8716 - accuracy: 0.3939\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8640 - accuracy: 0.40 - 0s 3ms/step - loss: 1.8675 - accuracy: 0.3939\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8548 - accuracy: 0.40 - 0s 4ms/step - loss: 1.8636 - accuracy: 0.3939\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8622 - accuracy: 0.40 - 0s 3ms/step - loss: 1.8599 - accuracy: 0.3939\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8593 - accuracy: 0.40 - 0s 4ms/step - loss: 1.8564 - accuracy: 0.3939\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8363 - accuracy: 0.40 - 0s 3ms/step - loss: 1.8535 - accuracy: 0.3939\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8548 - accuracy: 0.40 - 0s 3ms/step - loss: 1.8504 - accuracy: 0.4242\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8515 - accuracy: 0.46 - 0s 4ms/step - loss: 1.8480 - accuracy: 0.4848\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8500 - accuracy: 0.50 - 0s 4ms/step - loss: 1.8457 - accuracy: 0.5152\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8484 - accuracy: 0.50 - 0s 4ms/step - loss: 1.8435 - accuracy: 0.5152\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8312 - accuracy: 0.53 - 0s 3ms/step - loss: 1.8423 - accuracy: 0.5152\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8539 - accuracy: 0.50 - 0s 4ms/step - loss: 1.8394 - accuracy: 0.5152\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8420 - accuracy: 0.46 - 0s 3ms/step - loss: 1.8358 - accuracy: 0.4848\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8371 - accuracy: 0.46 - 0s 4ms/step - loss: 1.8326 - accuracy: 0.4545\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8089 - accuracy: 0.46 - 0s 3ms/step - loss: 1.8282 - accuracy: 0.4545\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8117 - accuracy: 0.46 - 0s 4ms/step - loss: 1.8230 - accuracy: 0.4545\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8238 - accuracy: 0.50 - 0s 3ms/step - loss: 1.8188 - accuracy: 0.4848\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7948 - accuracy: 0.50 - 0s 4ms/step - loss: 1.8149 - accuracy: 0.4848\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7922 - accuracy: 0.50 - 0s 3ms/step - loss: 1.8114 - accuracy: 0.4848\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7973 - accuracy: 0.50 - 0s 4ms/step - loss: 1.8088 - accuracy: 0.4848\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8112 - accuracy: 0.50 - 0s 3ms/step - loss: 1.8064 - accuracy: 0.4848\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8090 - accuracy: 0.50 - 0s 4ms/step - loss: 1.8027 - accuracy: 0.5152\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7875 - accuracy: 0.53 - 0s 3ms/step - loss: 1.7980 - accuracy: 0.5152\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8004 - accuracy: 0.50 - 0s 3ms/step - loss: 1.7942 - accuracy: 0.5152\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7985 - accuracy: 0.50 - 0s 3ms/step - loss: 1.7913 - accuracy: 0.5152\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7766 - accuracy: 0.53 - 0s 3ms/step - loss: 1.7897 - accuracy: 0.5152\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7957 - accuracy: 0.50 - 0s 3ms/step - loss: 1.7867 - accuracy: 0.5152\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7955 - accuracy: 0.50 - 0s 3ms/step - loss: 1.7839 - accuracy: 0.5152\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7698 - accuracy: 0.53 - 0s 3ms/step - loss: 1.7799 - accuracy: 0.5152\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7656 - accuracy: 0.53 - 0s 3ms/step - loss: 1.7728 - accuracy: 0.5152\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7710 - accuracy: 0.50 - 0s 3ms/step - loss: 1.7648 - accuracy: 0.5152\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7682 - accuracy: 0.50 - 0s 3ms/step - loss: 1.7575 - accuracy: 0.5152\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7412 - accuracy: 0.53 - 0s 3ms/step - loss: 1.7538 - accuracy: 0.5152\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7420 - accuracy: 0.43 - 0s 3ms/step - loss: 1.7498 - accuracy: 0.4242\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7267 - accuracy: 0.40 - 0s 3ms/step - loss: 1.7474 - accuracy: 0.3939\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7626 - accuracy: 0.37 - 0s 3ms/step - loss: 1.7450 - accuracy: 0.3939\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7450 - accuracy: 0.40 - 0s 3ms/step - loss: 1.7429 - accuracy: 0.3939\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7244 - accuracy: 0.40 - 0s 3ms/step - loss: 1.7393 - accuracy: 0.3939\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7470 - accuracy: 0.37 - 0s 3ms/step - loss: 1.7341 - accuracy: 0.3939\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7435 - accuracy: 0.37 - 0s 3ms/step - loss: 1.7289 - accuracy: 0.3939\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7460 - accuracy: 0.37 - 0s 3ms/step - loss: 1.7254 - accuracy: 0.3939\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6986 - accuracy: 0.40 - 0s 3ms/step - loss: 1.7204 - accuracy: 0.3939\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7337 - accuracy: 0.37 - 0s 3ms/step - loss: 1.7133 - accuracy: 0.3939\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6852 - accuracy: 0.40 - 0s 3ms/step - loss: 1.7068 - accuracy: 0.3939\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7216 - accuracy: 0.37 - 0s 3ms/step - loss: 1.7005 - accuracy: 0.3939\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7181 - accuracy: 0.37 - 0s 3ms/step - loss: 1.6946 - accuracy: 0.3939\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6830 - accuracy: 0.40 - 0s 3ms/step - loss: 1.6886 - accuracy: 0.3939\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6635 - accuracy: 0.40 - 0s 3ms/step - loss: 1.6825 - accuracy: 0.3939\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6966 - accuracy: 0.37 - 0s 3ms/step - loss: 1.6767 - accuracy: 0.3939\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6551 - accuracy: 0.40 - 0s 3ms/step - loss: 1.6715 - accuracy: 0.3939\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6532 - accuracy: 0.40 - 0s 4ms/step - loss: 1.6660 - accuracy: 0.3939\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6617 - accuracy: 0.40 - 0s 3ms/step - loss: 1.6607 - accuracy: 0.3939\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6464 - accuracy: 0.40 - 0s 4ms/step - loss: 1.6558 - accuracy: 0.3939\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6295 - accuracy: 0.43 - 0s 3ms/step - loss: 1.6514 - accuracy: 0.4242\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6264 - accuracy: 0.50 - 0s 4ms/step - loss: 1.6477 - accuracy: 0.4848\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6641 - accuracy: 0.50 - 0s 3ms/step - loss: 1.6455 - accuracy: 0.5152\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6665 - accuracy: 0.50 - 0s 3ms/step - loss: 1.6422 - accuracy: 0.5152\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6161 - accuracy: 0.53 - 0s 3ms/step - loss: 1.6376 - accuracy: 0.5152\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6178 - accuracy: 0.53 - 0s 3ms/step - loss: 1.6335 - accuracy: 0.5152\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6310 - accuracy: 0.50 - 0s 3ms/step - loss: 1.6293 - accuracy: 0.5152\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6436 - accuracy: 0.50 - 0s 3ms/step - loss: 1.6242 - accuracy: 0.5152\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6044 - accuracy: 0.53 - 0s 3ms/step - loss: 1.6180 - accuracy: 0.5152\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6225 - accuracy: 0.46 - 0s 5ms/step - loss: 1.6109 - accuracy: 0.4848\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6058 - accuracy: 0.40 - 0s 3ms/step - loss: 1.6060 - accuracy: 0.3939\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6183 - accuracy: 0.37 - 0s 4ms/step - loss: 1.6025 - accuracy: 0.3939\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5913 - accuracy: 0.40 - 0s 4ms/step - loss: 1.6019 - accuracy: 0.3939\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5791 - accuracy: 0.40 - 0s 4ms/step - loss: 1.6030 - accuracy: 0.3939\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5928 - accuracy: 0.40 - 0s 5ms/step - loss: 1.6028 - accuracy: 0.3939\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5914 - accuracy: 0.40 - 0s 4ms/step - loss: 1.6010 - accuracy: 0.3939\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5785 - accuracy: 0.40 - 0s 4ms/step - loss: 1.5981 - accuracy: 0.3939\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5698 - accuracy: 0.40 - 0s 5ms/step - loss: 1.5918 - accuracy: 0.3939\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6111 - accuracy: 0.37 - 0s 4ms/step - loss: 1.5833 - accuracy: 0.3939\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5995 - accuracy: 0.37 - 0s 3ms/step - loss: 1.5744 - accuracy: 0.3939\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5765 - accuracy: 0.37 - 0s 4ms/step - loss: 1.5651 - accuracy: 0.3939\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5739 - accuracy: 0.37 - 0s 4ms/step - loss: 1.5573 - accuracy: 0.3939\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5483 - accuracy: 0.43 - 0s 4ms/step - loss: 1.5493 - accuracy: 0.4545\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5428 - accuracy: 0.43 - 0s 4ms/step - loss: 1.5432 - accuracy: 0.4545\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5281 - accuracy: 0.53 - 0s 4ms/step - loss: 1.5389 - accuracy: 0.5152\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 0.53 - 0s 4ms/step - loss: 1.5349 - accuracy: 0.5152\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5246 - accuracy: 0.53 - 0s 4ms/step - loss: 1.5306 - accuracy: 0.5152\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5385 - accuracy: 0.50 - 0s 3ms/step - loss: 1.5270 - accuracy: 0.5152\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5422 - accuracy: 0.50 - 0s 3ms/step - loss: 1.5209 - accuracy: 0.5152\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5019 - accuracy: 0.53 - 0s 3ms/step - loss: 1.5146 - accuracy: 0.5152\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4960 - accuracy: 0.53 - 0s 3ms/step - loss: 1.5086 - accuracy: 0.5152\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4832 - accuracy: 0.53 - 0s 3ms/step - loss: 1.5039 - accuracy: 0.5152\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 0.43 - 0s 3ms/step - loss: 1.4994 - accuracy: 0.4545\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4886 - accuracy: 0.46 - 0s 4ms/step - loss: 1.4944 - accuracy: 0.4545\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4782 - accuracy: 0.46 - 0s 4ms/step - loss: 1.4892 - accuracy: 0.4545\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4829 - accuracy: 0.43 - 0s 3ms/step - loss: 1.4844 - accuracy: 0.4545\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.46 - 0s 3ms/step - loss: 1.4793 - accuracy: 0.4545\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4904 - accuracy: 0.50 - 0s 3ms/step - loss: 1.4742 - accuracy: 0.5152\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4973 - accuracy: 0.50 - 0s 4ms/step - loss: 1.4688 - accuracy: 0.5152\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4934 - accuracy: 0.50 - 0s 3ms/step - loss: 1.4641 - accuracy: 0.5152\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4902 - accuracy: 0.50 - 0s 3ms/step - loss: 1.4608 - accuracy: 0.5152\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4507 - accuracy: 0.53 - 0s 3ms/step - loss: 1.4592 - accuracy: 0.5152\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4710 - accuracy: 0.50 - 0s 3ms/step - loss: 1.4581 - accuracy: 0.5152\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4293 - accuracy: 0.53 - 0s 3ms/step - loss: 1.4528 - accuracy: 0.5152\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4774 - accuracy: 0.50 - 0s 4ms/step - loss: 1.4436 - accuracy: 0.5152\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4330 - accuracy: 0.50 - 0s 3ms/step - loss: 1.4357 - accuracy: 0.5152\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4460 - accuracy: 0.50 - 0s 3ms/step - loss: 1.4298 - accuracy: 0.5152\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4473 - accuracy: 0.50 - 0s 3ms/step - loss: 1.4246 - accuracy: 0.5152\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4113 - accuracy: 0.53 - 0s 4ms/step - loss: 1.4209 - accuracy: 0.5152\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4533 - accuracy: 0.50 - 0s 4ms/step - loss: 1.4188 - accuracy: 0.5152\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4392 - accuracy: 0.43 - 0s 3ms/step - loss: 1.4177 - accuracy: 0.4545\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.3908 - accuracy: 0.46 - 0s 3ms/step - loss: 1.4146 - accuracy: 0.4545\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4056 - accuracy: 0.43 - 0s 4ms/step - loss: 1.4091 - accuracy: 0.4545\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3925 - accuracy: 0.53 - 0s 4ms/step - loss: 1.4027 - accuracy: 0.5152\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4322 - accuracy: 0.50 - 0s 3ms/step - loss: 1.3964 - accuracy: 0.5152\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3570 - accuracy: 0.53 - 0s 4ms/step - loss: 1.3917 - accuracy: 0.5152\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4220 - accuracy: 0.50 - 0s 3ms/step - loss: 1.3875 - accuracy: 0.5152\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4063 - accuracy: 0.50 - 0s 4ms/step - loss: 1.3846 - accuracy: 0.5152\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4168 - accuracy: 0.50 - 0s 3ms/step - loss: 1.3818 - accuracy: 0.5152\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3630 - accuracy: 0.53 - 0s 4ms/step - loss: 1.3791 - accuracy: 0.5152\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3742 - accuracy: 0.50 - 0s 3ms/step - loss: 1.3756 - accuracy: 0.5152\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3695 - accuracy: 0.50 - 0s 4ms/step - loss: 1.3711 - accuracy: 0.5152\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3847 - accuracy: 0.50 - 0s 3ms/step - loss: 1.3677 - accuracy: 0.5152\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3992 - accuracy: 0.50 - 0s 4ms/step - loss: 1.3624 - accuracy: 0.5152\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3472 - accuracy: 0.53 - 0s 3ms/step - loss: 1.3563 - accuracy: 0.5152\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3417 - accuracy: 0.53 - 0s 4ms/step - loss: 1.3508 - accuracy: 0.5152\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3818 - accuracy: 0.50 - 0s 3ms/step - loss: 1.3461 - accuracy: 0.5152\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3324 - accuracy: 0.53 - 0s 4ms/step - loss: 1.3419 - accuracy: 0.5152\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3731 - accuracy: 0.50 - 0s 3ms/step - loss: 1.3380 - accuracy: 0.5152\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3708 - accuracy: 0.50 - 0s 4ms/step - loss: 1.3343 - accuracy: 0.5152\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3325 - accuracy: 0.50 - 0s 3ms/step - loss: 1.3312 - accuracy: 0.5152\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3190 - accuracy: 0.53 - 0s 4ms/step - loss: 1.3283 - accuracy: 0.5152\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3243 - accuracy: 0.50 - 0s 3ms/step - loss: 1.3241 - accuracy: 0.5152\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3002 - accuracy: 0.53 - 0s 4ms/step - loss: 1.3193 - accuracy: 0.5152\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3001 - accuracy: 0.53 - 0s 3ms/step - loss: 1.3144 - accuracy: 0.5152\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3126 - accuracy: 0.50 - 0s 4ms/step - loss: 1.3099 - accuracy: 0.5152\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2814 - accuracy: 0.53 - 0s 3ms/step - loss: 1.3055 - accuracy: 0.5152\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2933 - accuracy: 0.53 - 0s 4ms/step - loss: 1.3015 - accuracy: 0.5152\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3182 - accuracy: 0.50 - 0s 3ms/step - loss: 1.2974 - accuracy: 0.5152\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3256 - accuracy: 0.50 - 0s 4ms/step - loss: 1.2931 - accuracy: 0.5152\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2659 - accuracy: 0.53 - 0s 3ms/step - loss: 1.2885 - accuracy: 0.5152\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3016 - accuracy: 0.50 - 0s 4ms/step - loss: 1.2845 - accuracy: 0.5152\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2594 - accuracy: 0.53 - 0s 3ms/step - loss: 1.2806 - accuracy: 0.5152\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2778 - accuracy: 0.50 - 0s 4ms/step - loss: 1.2779 - accuracy: 0.5152\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2347 - accuracy: 0.53 - 0s 3ms/step - loss: 1.2737 - accuracy: 0.5152\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2483 - accuracy: 0.53 - 0s 4ms/step - loss: 1.2674 - accuracy: 0.5152\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2748 - accuracy: 0.50 - 0s 3ms/step - loss: 1.2617 - accuracy: 0.5152\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2561 - accuracy: 0.50 - 0s 4ms/step - loss: 1.2562 - accuracy: 0.5152\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2519 - accuracy: 0.50 - 0s 3ms/step - loss: 1.2507 - accuracy: 0.5152\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2470 - accuracy: 0.50 - 0s 3ms/step - loss: 1.2451 - accuracy: 0.5152\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2020 - accuracy: 0.53 - 0s 3ms/step - loss: 1.2411 - accuracy: 0.5152\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2504 - accuracy: 0.50 - 0s 3ms/step - loss: 1.2383 - accuracy: 0.5152\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2586 - accuracy: 0.50 - 0s 3ms/step - loss: 1.2337 - accuracy: 0.5152\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2242 - accuracy: 0.53 - 0s 3ms/step - loss: 1.2280 - accuracy: 0.5152\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2124 - accuracy: 0.53 - 0s 3ms/step - loss: 1.2218 - accuracy: 0.5152\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2198 - accuracy: 0.50 - 0s 4ms/step - loss: 1.2163 - accuracy: 0.5152\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1967 - accuracy: 0.53 - 0s 3ms/step - loss: 1.2109 - accuracy: 0.5152\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2376 - accuracy: 0.50 - 0s 4ms/step - loss: 1.2074 - accuracy: 0.5152\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1996 - accuracy: 0.56 - 0s 3ms/step - loss: 1.2045 - accuracy: 0.5455\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2289 - accuracy: 0.53 - 0s 4ms/step - loss: 1.2031 - accuracy: 0.5455\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1790 - accuracy: 0.56 - 0s 3ms/step - loss: 1.2010 - accuracy: 0.5455\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2219 - accuracy: 0.53 - 0s 4ms/step - loss: 1.1959 - accuracy: 0.5455\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2123 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1896 - accuracy: 0.5455\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2124 - accuracy: 0.53 - 0s 4ms/step - loss: 1.1836 - accuracy: 0.5455\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1577 - accuracy: 0.56 - 0s 3ms/step - loss: 1.1781 - accuracy: 0.5455\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1929 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1734 - accuracy: 0.5455\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1741 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1696 - accuracy: 0.5455\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1517 - accuracy: 0.56 - 0s 4ms/step - loss: 1.1661 - accuracy: 0.5455\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1833 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1628 - accuracy: 0.5455\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.1583 - accuracy: 0.56 - 0s 4ms/step - loss: 1.1582 - accuracy: 0.5455\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1821 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1528 - accuracy: 0.5455\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1767 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1474 - accuracy: 0.5455\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1429 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1425 - accuracy: 0.5455\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1368 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1374 - accuracy: 0.5455\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1333 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1329 - accuracy: 0.5455\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1305 - accuracy: 0.56 - 0s 3ms/step - loss: 1.1298 - accuracy: 0.5455\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1135 - accuracy: 0.56 - 0s 3ms/step - loss: 1.1272 - accuracy: 0.5455\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1273 - accuracy: 0.53 - 0s 4ms/step - loss: 1.1249 - accuracy: 0.5455\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1534 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1242 - accuracy: 0.5455\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1524 - accuracy: 0.53 - 0s 4ms/step - loss: 1.1231 - accuracy: 0.5455\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1012 - accuracy: 0.56 - 0s 3ms/step - loss: 1.1207 - accuracy: 0.5455\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1401 - accuracy: 0.53 - 0s 3ms/step - loss: 1.1136 - accuracy: 0.5455\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0926 - accuracy: 0.56 - 0s 3ms/step - loss: 1.1051 - accuracy: 0.5455\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0819 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0997 - accuracy: 0.5455\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0822 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0951 - accuracy: 0.5455\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0840 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0939 - accuracy: 0.5455\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1122 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0950 - accuracy: 0.5758\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1179 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0974 - accuracy: 0.5758\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0820 - accuracy: 0.59 - 0s 3ms/step - loss: 1.0984 - accuracy: 0.5758\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1162 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0941 - accuracy: 0.5758\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1166 - accuracy: 0.53 - 0s 3ms/step - loss: 1.0871 - accuracy: 0.5455\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0668 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0799 - accuracy: 0.5455\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0989 - accuracy: 0.53 - 0s 3ms/step - loss: 1.0702 - accuracy: 0.5455\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0623 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0615 - accuracy: 0.5758\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0485 - accuracy: 0.59 - 0s 3ms/step - loss: 1.0565 - accuracy: 0.5758\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0784 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0538 - accuracy: 0.5758\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0112 - accuracy: 0.59 - 0s 3ms/step - loss: 1.0529 - accuracy: 0.5758\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0666 - accuracy: 0.59 - 0s 3ms/step - loss: 1.0524 - accuracy: 0.6061\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0481 - accuracy: 0.62 - 0s 3ms/step - loss: 1.0492 - accuracy: 0.6061\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0431 - accuracy: 0.59 - 0s 3ms/step - loss: 1.0430 - accuracy: 0.6061\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0544 - accuracy: 0.59 - 0s 3ms/step - loss: 1.0365 - accuracy: 0.6061\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9913 - accuracy: 0.62 - 0s 3ms/step - loss: 1.0305 - accuracy: 0.6061\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0155 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0261 - accuracy: 0.5455\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0117 - accuracy: 0.56 - 0s 4ms/step - loss: 1.0229 - accuracy: 0.5455\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0116 - accuracy: 0.56 - 0s 3ms/step - loss: 1.0203 - accuracy: 0.5455\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0096 - accuracy: 0.59 - 0s 4ms/step - loss: 1.0176 - accuracy: 0.5758\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0336 - accuracy: 0.59 - 0s 3ms/step - loss: 1.0159 - accuracy: 0.6061\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0052 - accuracy: 0.62 - 0s 3ms/step - loss: 1.0138 - accuracy: 0.6061\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9896 - accuracy: 0.62 - 0s 3ms/step - loss: 1.0123 - accuracy: 0.6061\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9945 - accuracy: 0.62 - 0s 3ms/step - loss: 1.0086 - accuracy: 0.6061\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9654 - accuracy: 0.62 - 0s 3ms/step - loss: 1.0036 - accuracy: 0.6061\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0247 - accuracy: 0.65 - 0s 3ms/step - loss: 0.9973 - accuracy: 0.6667\n",
      "Epoch 334/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0171 - accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.90 - 0s 5ms/step - loss: 0.6451 - accuracy: 0.9091\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.90 - 0s 4ms/step - loss: 0.6398 - accuracy: 0.9091\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6495 - accuracy: 0.90 - 0s 3ms/step - loss: 0.6339 - accuracy: 0.9091\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.90 - 0s 3ms/step - loss: 0.6288 - accuracy: 0.9091\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.90 - 0s 3ms/step - loss: 0.6237 - accuracy: 0.9091\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6274 - accuracy: 0.90 - 0s 3ms/step - loss: 0.6181 - accuracy: 0.9091\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5840 - accuracy: 0.93 - 0s 3ms/step - loss: 0.6151 - accuracy: 0.9091\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.87 - 0s 3ms/step - loss: 0.6132 - accuracy: 0.8788\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.87 - 0s 3ms/step - loss: 0.6106 - accuracy: 0.8788\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.87 - 0s 3ms/step - loss: 0.6101 - accuracy: 0.8788\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.87 - 0s 3ms/step - loss: 0.6097 - accuracy: 0.8788\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.87 - 0s 3ms/step - loss: 0.6059 - accuracy: 0.8788\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.87 - 0s 3ms/step - loss: 0.5991 - accuracy: 0.8788\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.90 - 0s 3ms/step - loss: 0.5929 - accuracy: 0.8788\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.87 - 0s 4ms/step - loss: 0.5897 - accuracy: 0.8788\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6016 - accuracy: 0.87 - 0s 3ms/step - loss: 0.5869 - accuracy: 0.8788\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.87 - 0s 3ms/step - loss: 0.5845 - accuracy: 0.8788\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.84 - 0s 3ms/step - loss: 0.5826 - accuracy: 0.8485\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.84 - 0s 3ms/step - loss: 0.5801 - accuracy: 0.8485\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5689 - accuracy: 0.84 - 0s 3ms/step - loss: 0.5747 - accuracy: 0.8485\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.90 - 0s 3ms/step - loss: 0.5685 - accuracy: 0.9091\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5636 - accuracy: 0.9091\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.90 - 0s 3ms/step - loss: 0.5583 - accuracy: 0.9091\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5541 - accuracy: 0.9091\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.90 - 0s 3ms/step - loss: 0.5516 - accuracy: 0.9091\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.90 - 0s 3ms/step - loss: 0.5479 - accuracy: 0.9091\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.90 - 0s 4ms/step - loss: 0.5429 - accuracy: 0.9091\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.90 - 0s 4ms/step - loss: 0.5380 - accuracy: 0.9091\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.93 - 0s 4ms/step - loss: 0.5355 - accuracy: 0.9091\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.90 - 0s 4ms/step - loss: 0.5352 - accuracy: 0.9091\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5330 - accuracy: 0.9394\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5290 - accuracy: 0.9394\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5248 - accuracy: 0.9394\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.93 - 0s 4ms/step - loss: 0.5207 - accuracy: 0.9394\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5181 - accuracy: 0.9394\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5159 - accuracy: 0.9394\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5134 - accuracy: 0.9394\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.93 - 0s 4ms/step - loss: 0.5108 - accuracy: 0.9394\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5085 - accuracy: 0.9394\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5056 - accuracy: 0.9394\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.93 - 0s 3ms/step - loss: 0.5023 - accuracy: 0.9394\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4993 - accuracy: 0.9394\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4910 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4965 - accuracy: 0.9394\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5074 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4932 - accuracy: 0.9394\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4902 - accuracy: 0.9394\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4874 - accuracy: 0.9394\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4847 - accuracy: 0.9394\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4818 - accuracy: 0.9394\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4835 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4784 - accuracy: 0.9394\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4752 - accuracy: 0.9394\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4723 - accuracy: 0.9394\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4666 - accuracy: 0.93 - 0s 4ms/step - loss: 0.4697 - accuracy: 0.9394\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4664 - accuracy: 0.9394\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4739 - accuracy: 0.90 - 0s 4ms/step - loss: 0.4600 - accuracy: 0.9091\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.90 - 0s 4ms/step - loss: 0.4569 - accuracy: 0.9091\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4677 - accuracy: 0.93 - 0s 4ms/step - loss: 0.4545 - accuracy: 0.9394\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4486 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4541 - accuracy: 0.9394\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.4478 - accuracy: 0.93 - 0s 4ms/step - loss: 0.4521 - accuracy: 0.9394\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4510 - accuracy: 0.9394\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.93 - 0s 4ms/step - loss: 0.4495 - accuracy: 0.9394\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4457 - accuracy: 0.9394\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4407 - accuracy: 0.9394\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4218 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4360 - accuracy: 0.9394\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.93 - 0s 4ms/step - loss: 0.4320 - accuracy: 0.9394\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4287 - accuracy: 0.9394\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4271 - accuracy: 0.9394\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4270 - accuracy: 0.9394\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.93 - 0s 3ms/step - loss: 0.4281 - accuracy: 0.9394\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.93 - 0s 4ms/step - loss: 0.4282 - accuracy: 0.9394\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.93 - 0s 4ms/step - loss: 0.4253 - accuracy: 0.9394\n"
     ]
    }
   ],
   "source": [
    "# fitting the model on the training labels and training sequences\n",
    "epochs = 500\n",
    "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6617a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: chat_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# save all the required files in order to use it at the inference time. \n",
    "# we save the trained model, fitted tokenizer object and fitted label encoder object.\n",
    "\n",
    "# to save the trained model\n",
    "model.save(\"chat_model\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# to save the fitted tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# to save the fitted label encoder\n",
    "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34024040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n",
      "User: Hi\n",
      "ChatBot: Hello\n",
      "User: What is your name?\n",
      "ChatBot: You can call me Joana.\n",
      "User: my name is prateek\n",
      "ChatBot: Hi there\n",
      "User: Can you open the door\n",
      "ChatBot: Hi there\n",
      "User: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;66;03m# print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(Fore\u001b[38;5;241m.\u001b[39mYELLOW \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart messaging with the bot (type quit to stop)!\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m Style\u001b[38;5;241m.\u001b[39mRESET_ALL)\n\u001b[1;32m---> 49\u001b[0m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(Fore\u001b[38;5;241m.\u001b[39mLIGHTBLUE_EX \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m Style\u001b[38;5;241m.\u001b[39mRESET_ALL, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inp\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m     )\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a21c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca24c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
