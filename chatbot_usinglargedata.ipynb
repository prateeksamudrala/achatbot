{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a75176f",
   "metadata": {},
   "source": [
    "# Loading, Extracting and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c320e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bff516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "with open('Intents_bigfile.json') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5490fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing function\n",
    "def preprocessing(line):\n",
    "    line = re.sub(r'[^a-zA-z.?!\\']', ' ', line)\n",
    "    line = re.sub(r'[ ]+', ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf8a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting intent, text and response data after using the preprocessing function\n",
    "\n",
    "inputs, targets = [], []\n",
    "classes = []\n",
    "intent_doc = {}\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    if intent['intent'] not in classes:\n",
    "        classes.append(intent['intent'])\n",
    "    if intent['intent'] not in intent_doc:\n",
    "        intent_doc[intent['intent']] = []\n",
    "        \n",
    "    for text in intent['text']:\n",
    "        inputs.append(preprocessing(text))\n",
    "        targets.append(intent['intent'])\n",
    "        \n",
    "    for response in intent['responses']:\n",
    "        intent_doc[intent['intent']].append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811d5db",
   "metadata": {},
   "source": [
    "# Tokenizing input data and creating categorical targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d50d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization is a method to segregate a particular text into small chunks or tokens. \n",
    "# Here the tokens or chunks can be anything from words to characters, even subwords.\n",
    "def tokenize_data(input_list):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n",
    "    \n",
    "    tokenizer.fit_on_texts(input_list)\n",
    "    \n",
    "    input_seq = tokenizer.texts_to_sequences(input_list)\n",
    "\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, padding='pre')\n",
    "    \n",
    "    return tokenizer, input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf13b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize input data\n",
    "tokenizer, input_tensor = tokenize_data(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "913ab706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_categorical_target(targets):\n",
    "    word={}\n",
    "    categorical_target=[]\n",
    "    counter=0\n",
    "    for trg in targets:\n",
    "        if trg not in word:\n",
    "            word[trg]=counter\n",
    "            counter+=1\n",
    "        categorical_target.append(word[trg])\n",
    "    \n",
    "    categorical_tensor = tf.keras.utils.to_categorical(categorical_target, num_classes=len(word), dtype='int32')\n",
    "    return categorical_tensor, dict((v,k) for k, v in word.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db643d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical target output data\n",
    "\n",
    "target_tensor, trg_index_word = create_categorical_target(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dadfe8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (143, 9) and output shape: (143, 22)\n"
     ]
    }
   ],
   "source": [
    "# How does our input and output look?\n",
    "print('input shape: {} and output shape: {}'.format(input_tensor.shape, target_tensor.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ae476",
   "metadata": {},
   "source": [
    "# Building model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51a8d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "epochs=50\n",
    "vocab_size=len(tokenizer.word_index) + 1\n",
    "embed_dim=512\n",
    "units=128\n",
    "target_length=target_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abbb2ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 512)         66048     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              656384    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 22)                2838      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 758,166\n",
      "Trainable params: 758,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recurrent Neural Network with Tensor flow\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, dropout=0.2)),\n",
    "    tf.keras.layers.Dense(units, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(target_length, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47cdefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d77208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 22ms/step - loss: 3.0941 - accuracy: 0.0909\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.6479 - accuracy: 0.2657\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.8712 - accuracy: 0.4755\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2177 - accuracy: 0.6154\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6717 - accuracy: 0.7832\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3628 - accuracy: 0.9021\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1504 - accuracy: 0.9510\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1123 - accuracy: 0.9580\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0637 - accuracy: 0.9720\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0364 - accuracy: 0.9930\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0252 - accuracy: 0.9930\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0328 - accuracy: 0.9860\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0176 - accuracy: 0.9930\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0158 - accuracy: 0.9930\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0346 - accuracy: 0.9860\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0055 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x290b5e07a00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(input_tensor, target_tensor, epochs=epochs, callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d809f",
   "metadata": {},
   "source": [
    "# The Chat Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69ab5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response function\n",
    "def response(sentence):\n",
    "    sent_seq = []\n",
    "    doc = nlp(repr(sentence))\n",
    "    \n",
    "    # split the input sentences into words\n",
    "    for token in doc:\n",
    "        if token.text in tokenizer.word_index:\n",
    "            sent_seq.append(tokenizer.word_index[token.text])\n",
    "\n",
    "        # handle the unknown words error\n",
    "        else:\n",
    "            sent_seq.append(tokenizer.word_index['<unk>'])\n",
    "\n",
    "    sent_seq = tf.expand_dims(sent_seq, 0)\n",
    "    # predict the category of input sentences\n",
    "    pred = model(sent_seq)\n",
    "\n",
    "    pred_class = np.argmax(pred.numpy(), axis=1)\n",
    "    \n",
    "    # choice a random response for predicted sentence\n",
    "    return random.choice(intent_doc[trg_index_word[pred_class[0]]]), trg_index_word[pred_class[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1378cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Enter 'quit' to break the loop.\n",
      "You: Hello!\n",
      "Bot: It's life Jim but not as we know it! \n",
      "\n",
      "You: What is your name?\n",
      "Bot: You are <HUMAN>! How can I help? \n",
      "\n",
      "You: Can you tell me a joke?\n",
      "Bot: A man goes into a bar and orders a pint. After a few minutes he hears a voice that says, 'Nice shoes'. He looks around but the whole bar is empty apart from the barman at the other end of the bar. A few minutes later he hears the voice again. This time it says, 'I like your shirt'. He beckons the barman over and tells him what's been happening to which the barman replies, 'Ah, that would be the nuts sir. They're complimentary'! \n",
      "\n",
      "You: Can you tell me the weather in Omaha?\n",
      "Bot: Let me see \n",
      "\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "# Bot function\n",
    "\n",
    "print(\"Note: Enter 'quit' to break the loop.\")\n",
    "while True:\n",
    "    input_ = input('You: ')\n",
    "    if input_.lower() == 'quit':\n",
    "        break\n",
    "    res, typ = response(input_)\n",
    "    print('Bot: {} '.format(res))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c8b20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ee040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
